{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Direitos autorais 2024 Google LLC\n",
        "#\n",
        "# Licenciado sob a Licen√ßa Apache, Vers√£o 2.0 (a \"Licen√ßa\");\n",
        "# voc√™ n√£o pode usar este arquivo exceto em conformidade com a Licen√ßa.\n",
        "# Voc√™ pode obter uma c√≥pia da Licen√ßa em\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# A menos que exigido pela lei aplic√°vel ou acordado por escrito, o software\n",
        "# distribu√≠do sob a Licen√ßa √© distribu√≠do \"COMO EST√Å\",\n",
        "# SEM GARANTIAS OU CONDI√á√ïES DE QUALQUER TIPO, expressas ou impl√≠citas.\n",
        "# Consulte a Licen√ßa para o idioma espec√≠fico que rege as permiss√µes e\n",
        "# limita√ß√µes sob a Licen√ßa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Engenharia de Prompt - Melhores pr√°ticas\n",
        "\n",
        "> ***NOTA:** Este notebook utiliza o modelo generativo PaLM, que atingir√° seu [data de descontinua√ß√£o em outubro de 2024](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text#model_versions). Consulte [este caderno atualizado](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb) para uma vers√£o que usa o modelo Gemini mais recente.\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/prompts/intro_prompt_design.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/prompts/intro_prompt_design.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/language/prompts/intro_prompt_design.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1s1s_tePIyu"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Polong Lin](https://github.com/polong-lin) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Vis√£o geral\n",
        "\n",
        "Este caderno aborda os fundamentos da engenharia de prompts, incluindo algumas pr√°ticas recomendadas.\n",
        "\n",
        "\n",
        "Saiba mais sobre o design de prompts na [documenta√ß√£o oficial](https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-overview)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### Objetivo\n",
        "\n",
        "Neste caderno, voc√™ aprender√° as pr√°ticas recomendadas em torno da engenharia de prompts ‚Äì como projetar prompts para melhorar a qualidade de suas respostas.\n",
        "\n",
        "Este notebook aborda as seguintes pr√°ticas recomendadas para design de prompts\n",
        "\n",
        "- Seja conciso\n",
        "- Seja espec√≠fico e bem definido\n",
        "- Pe√ßa uma tarefa de cada vez\n",
        "- Transforme tarefas generativas em tarefas de classifica√ß√£o\n",
        "- Melhore a qualidade da resposta incluindo exemplos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea013f50403c"
      },
      "source": [
        "### Custos\n",
        "Este tutorial usa componentes fatur√°veis ‚Äã‚Äãdo Google Cloud:\n",
        "\n",
        "* Est√∫dio de IA generativa da Vertex AI\n",
        "\n",
        "Saiba mais sobre [Vertex AI pre√ßos](https://cloud.google.com/vertex-ai/pricing),\n",
        " use o [Calculadora de pre√ßos](https://cloud.google.com/products/calculator/)\n",
        "para gerar uma estimativa de custo com base no uso projetado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e663cb43fa0"
      },
      "source": [
        "### Instalar o SDK da Vertex AI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82ad0c445061",
        "outputId": "bf20ab3f-0a6e-4fc0-da68-1b3c5ec39971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /home/jupyter/.local/lib/python3.10/site-packages (1.63.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /home/jupyter/.local/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.19.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.32.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /home/jupyter/.local/lib/python3.10/site-packages (from google-cloud-aiplatform) (4.25.4)\n",
            "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.14.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.5)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.5)\n",
            "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.17)\n",
            "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.2)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.1)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.7)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.24.4)\n",
            "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.26.19)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.7.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cebd6983cbad"
      },
      "source": [
        "**Observa√ß√£o:** Ignore os avisos de descontinua√ß√£o e erros de incompatibilidade relacionados √†s depend√™ncias do pip.\n",
        "\n",
        "**Colab only:** Execute a c√©lula a seguir para reiniciar o kernel ou use o bot√£o para reiniciar o kernel. Para **Vertex AI Workbench** voc√™ pode reiniciar o terminal usando o bot√£o na parte superior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bea801acf6b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "596062d2-1b0b-4a39-d8e4-06f6eb3e302f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Reinicie automaticamente o kernel ap√≥s a instala√ß√£o para que seu ambiente possa acessar os novos pacotes\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a386d25fa8f"
      },
      "source": [
        "### Autenticando seu ambiente de notebook\n",
        "\n",
        "- Se voc√™ estiver usando o **Colab** para executar este notebook, execute a c√©lula abaixo e continue.\n",
        "- Se voc√™ estiver usando o **Vertex AI Workbench**, confira as instru√ß√µes de configura√ß√£o [aqui](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bd1dca8e9a7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYdma7UoPIyy"
      },
      "source": [
        "- Se voc√™ estiver executando este notebook em um ambiente de desenvolvimento local:\n",
        "  - Instale o [Google Cloud SDK](https://cloud.google.com/sdk).\n",
        "  - Obtenha credenciais de autentica√ß√£o. Crie credenciais locais executando o seguinte comando e seguindo o fluxo oauth2 (leia mais sobre o comando [aqui](https://cloud.google.com/sdk/gcloud/reference/beta/auth/application-default/login)):\n",
        "\n",
        "    ```bash\n",
        "    gcloud auth application-default login\n",
        "    ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### Importar bibliotecas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue7q-YO3Scpp"
      },
      "source": [
        "**Colab only:** Execute a c√©lula a seguir para inicializar o SDK da Vertex AI. Para o Vertex AI Workbench, voc√™ n√£o precisa executar isso.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGvWtLAyScpp"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "\n",
        "PROJECT_ID = \"qwiklabs-gcp-02-4b320c1cc30e\"  # @param {type:\"string\"}\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "from vertexai.language_models import TextGenerationModel\n",
        "from vertexai.language_models import ChatModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP76a2la7O-a"
      },
      "source": [
        "### Carregar o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7isig7e07O-a",
        "outputId": "679cef95-8134-40c1-b60c-eebebdb5a80c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1724617248.435049    5899 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n"
          ]
        }
      ],
      "source": [
        "generation_model = TextGenerationModel.from_pretrained(\"text-bison\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIPcn5dZ7O-b"
      },
      "source": [
        "## Pr√°ticas recomendadas de Engenharia de Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df7d153f4928"
      },
      "source": [
        "A engenharia de prompts trata de como projetar seus prompts para que a resposta seja o que voc√™ realmente esperava ver.\n",
        "\n",
        "A ideia de usar prompts \"pouco sofisticados\" √© minimizar o ru√≠do (informa√ß√µes desnecess√°rias ou confusas) em seu prompt para reduzir a possibilidade de o LLM (Modelo de Linguagem de Grande Escala)interpretar mal a inten√ß√£o do prompt. Abaixo est√£o algumas diretrizes sobre como projetar prompts \"pouco sofisticados\".\n",
        "\n",
        "Nesta se√ß√£o, voc√™ abordar√° as seguintes pr√°ticas recomendadas √† engenharia de prompts:\n",
        "\n",
        "* Seja conciso\n",
        "* Seja espec√≠fico e bem definido\n",
        "* Pe√ßa uma tarefa de cada vez\n",
        "* Melhore a qualidade da resposta incluindo exemplos\n",
        "* Transforme tarefas generativas em tarefas de classifica√ß√£o para melhorar a seguran√ßa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43c1169ac435"
      },
      "source": [
        "### Seja conciso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0f380f1620e"
      },
      "source": [
        "üõë N√£o recomendado. O prompt abaixo √© desnecessariamente detalhado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6a1697c3603",
        "outputId": "2f22ac3b-181c-4c8f-a7a3-82cd70e804fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Here are some potential names for a flower shop that specializes in selling bouquets of dried flowers:\n",
            "\n",
            "- Everlasting Blooms\n",
            "- Dried Flower Delights\n",
            "- Nature's Treasures\n",
            "- Rustic Florals\n",
            "- Timeless Botanicals\n",
            "- Floral Keepsakes\n",
            "- Dried Flower Gallery\n",
            "- Botanical Memories\n",
            "- Forever Flowers\n",
            "- Pressed Petals\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What do you think could be a good name for a flower shop that specializes in selling bouquets of dried flowers more than fresh flowers? Thank you!\"\n",
        "\n",
        "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2307f56a9b75"
      },
      "source": [
        "‚úÖ Recomendado. O prompt abaixo √© direto e conciso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc666404f47c",
        "outputId": "25b0fbe9-8792-496a-b31d-ac4157e41a0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " **The Everlasting Bloom**\n",
            "**Dried Delights**\n",
            "**Nature's Treasures**\n",
            "**Rustic Blooms**\n",
            "**Vintage Florals**\n",
            "**Dried Floral Creations**\n",
            "**Preserved Petals**\n",
            "**Eternal Elegance**\n",
            "**Botanical Beauties**\n",
            "**Nature's Keepsakes**\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Suggest a name for a flower shop that sells bouquets of dried flowers\"\n",
        "\n",
        "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17f6c48bba91"
      },
      "source": [
        "### Seja espec√≠fico e bem definido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "269b428e1563"
      },
      "source": [
        "*Suponha* que voc√™ queira pensar em maneiras criativas de descrever a Terra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6436ee2ff406"
      },
      "source": [
        "üõë N√£o recomendado. O prompt abaixo √© muito gen√©rico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "261b7f6e94c5",
        "outputId": "138bf176-9554-45a5-a12b-a99e253e1708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Earth is the third planet from the Sun and the only astronomical object known to harbor life. While larger than Mercury and Venus, Earth is smaller than Mars and the gas and ice giants of the outer Solar System. Earth is the only planet in our solar system not named after a Greek or Roman deity. Instead, its name comes from the Old English word \"erda,\" which means \"ground\" or \"soil.\"\n",
            "\n",
            "Earth is the only planet in the Solar System known to support life. It is the only planet with liquid water on its surface, and it has a breathable atmosphere. Earth is also the only planet with a magnetic field, which protects it from harmful solar radiation.\n",
            "\n",
            "Earth is a dynamic planet. Its climate is constantly changing, and its surface is constantly being reshaped by geological processes. Earth is also home to a wide variety of life forms, from microscopic bacteria to giant whales.\n",
            "\n",
            "Here are some of the key facts about Earth:\n",
            "\n",
            "* **Mass:** 5.972 √ó 10^24 kilograms\n",
            "* **Volume:** 1.08321 √ó 10^12 cubic kilometers\n",
            "* **Density:** 5,515 kilograms per cubic meter\n",
            "* **Surface area:** 510\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Tell me about Earth\"\n",
        "\n",
        "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bebfecd2912"
      },
      "source": [
        "‚úÖ Recomendado. O prompt abaixo √© espec√≠fico e bem definido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "242b1b3bae6e",
        "outputId": "f3d12186-8d69-4cbf-8ef4-755a6de1f6c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " **Earth's unique characteristics that set it apart from other planets include:**\n",
            "\n",
            "1. **Liquid Water:** Earth is the only known planet in our solar system with liquid water on its surface. This is essential for life as we know it, as water is a key component of all living organisms.\n",
            "\n",
            "2. **Oxygen-Rich Atmosphere:** Earth's atmosphere is composed of approximately 21% oxygen, which is essential for respiration and the survival of most life forms.\n",
            "\n",
            "3. **Plate Tectonics:** Earth is the only planet known to have active plate tectonics, which is the movement of the Earth's crust. This process creates mountains, volcanoes, and other geological features, and also plays a role in recycling the Earth's materials.\n",
            "\n",
            "4. **Magnetic Field:** Earth's magnetic field is generated by the movement of molten iron in the Earth's core. This field protects the planet from harmful solar radiation and cosmic rays, making it possible for life to exist on the surface.\n",
            "\n",
            "5. **Biodiversity:** Earth is home to an incredibly diverse array of life forms, from microscopic organisms to large mammals. This biodiversity is essential for maintaining the planet's ecosystems and providing resources for human survival.\n",
            "\n",
            "6. **Moderate Temperature Range:** Earth\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Generate a list of ways that makes Earth unique compared to other planets\"\n",
        "\n",
        "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20dca9a05eab"
      },
      "source": [
        "### Pe√ßa uma tarefa de cada vez\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9019d443179"
      },
      "source": [
        "üõë N√£o recomendado. O prompt abaixo tem duas partes para a pergunta que podem ser feitas separadamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70b3b5e5825d",
        "outputId": "c35211b1-f2a3-43ad-9018-c5d7e5832d0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " **The best method of boiling water:**\n",
            "\n",
            "The best method of boiling water depends on the situation and the equipment available. Here are a few common methods:\n",
            "\n",
            "1. **Electric kettle:** An electric kettle is a convenient and efficient way to boil water. It is quick and easy to use, and it automatically turns off when the water reaches the desired temperature.\n",
            "\n",
            "2. **Stovetop kettle:** A stovetop kettle is a traditional method of boiling water. It is placed on a stove or cooktop and heated until the water reaches the desired temperature. Stovetop kettles can be made of various materials, such as stainless steel, aluminum, or copper.\n",
            "\n",
            "3. **Microwave:** A microwave can be used to boil water quickly and easily. Place a microwave-safe container filled with water in the microwave and heat it on high power for 2-3 minutes, or until the water reaches the desired temperature.\n",
            "\n",
            "4. **Campfire:** If you are outdoors and do not have access to electricity or a stove, you can boil water over a campfire. Fill a pot or kettle with water and place it over the fire. Keep an eye on the water and remove it from the fire once it reaches the desired temperature.\n",
            "\n",
            "**Why is the sky blue?\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What's the best method of boiling water and why is the sky blue?\"\n",
        "\n",
        "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7936fb58c16a"
      },
      "source": [
        "‚úÖ Recomendado. Os prompts abaixo solicitam uma tarefa por vez."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2564dad6c8db",
        "outputId": "cea28429-6578-4660-f70d-d81067e267b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The best method of boiling water depends on the specific situation and available resources. Here are a few common methods:\n",
            "\n",
            "1. **Electric Kettle:**\n",
            "   - Electric kettles are designed specifically for boiling water and are very efficient.\n",
            "   - They heat water quickly and automatically turn off when the water reaches the boiling point.\n",
            "   - Electric kettles are convenient and safe to use.\n",
            "\n",
            "2. **Stovetop Kettle or Pot:**\n",
            "   - Traditional kettles or pots can be used to boil water on a stovetop.\n",
            "   - Fill the kettle or pot with water and place it on the stove over medium-high heat.\n",
            "   - Keep an eye on the water and remove it from the heat once it starts boiling.\n",
            "\n",
            "3. **Microwave:**\n",
            "   - Microwaves can be used to boil water quickly.\n",
            "   - Place a microwave-safe container filled with water in the microwave and heat it on high power for 2-3 minutes, depending on the amount of water.\n",
            "   - Be careful when handling the container as it will be hot.\n",
            "\n",
            "4. **Campfire or Outdoor Stove:**\n",
            "   - If you're outdoors, you can boil water over a campfire or using a portable outdoor stove.\n",
            "   -\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What's the best method of boiling water?\"\n",
        "\n",
        "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "770c695ade92",
        "outputId": "1a6a4dde-6e9a-4ffa-83cf-cd0915c6a499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The sky appears blue due to a phenomenon called Rayleigh scattering. This occurs when sunlight, which is composed of all colors of the visible spectrum, interacts with molecules in the Earth's atmosphere, primarily nitrogen and oxygen.\n",
            "\n",
            "When sunlight enters the atmosphere, it encounters these molecules and particles. The shorter wavelengths of light, such as blue and violet, are more likely to be scattered by these particles than the longer wavelengths, such as red and orange. This is because the shorter wavelengths have a higher frequency and interact more strongly with the molecules and particles in the atmosphere.\n",
            "\n",
            "As a result, the blue and violet light is scattered in all directions, creating the appearance of a blue sky. The other colors of the spectrum, such as red and orange, are less scattered and continue on their path towards the observer's eyes, contributing to the overall color of the sky.\n",
            "\n",
            "The amount of scattering depends on the wavelength of light and the density of the particles in the atmosphere. This is why the sky appears darker at night or during cloudy weather, as there are fewer particles to scatter the sunlight.\n",
            "\n",
            "Additionally, the position of the sun in the sky also affects the color of the sky. At sunrise and sunset, the sunlight has to travel through more of the atmosphere to reach our eyes\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Why is the sky blue?\"\n",
        "\n",
        "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff606011aa86"
      },
      "source": [
        "### Cuidado com as alucina√ß√µes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "956ce45b06a7"
      },
      "source": [
        "Embora os LLMs tenham sido treinados com uma grande quantidade de dados, eles podem gerar textos contendo afirma√ß√µes n√£o fundamentadas na verdade ou na realidade; essas respostas do LLM s√£o frequentemente chamadas de \"alucina√ß√µes\" devido √†s suas capacidades limitadas de memoriza√ß√£o. Observe que simplesmente solicitar que o LLM forne√ßa uma cita√ß√£o n√£o √© uma solu√ß√£o para esse problema, pois h√° casos de LLMs que fornecem cita√ß√µes falsas ou imprecisas. Lidar com alucina√ß√µes √© um desafio fundamental dos LLMs e de uma √°rea de pesquisa em andamento, por isso √© importante estar ciente de que os LLMs podem parecer fornecer afirma√ß√µes confiantes e que parecem corretas, mas que na verdade s√£o incorretas.\n",
        "\n",
        "Observe que se voc√™ pretende usar LLMs para casos de uso criativos, alucinar pode ser bastante √∫til."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c9d5f66179a"
      },
      "source": [
        "Tente o prompt como o abaixo repetidamente. Voc√™ pode notar que √†s vezes ele dir√° com seguran√ßa, mas de forma imprecisa, \"O primeiro elefante a visitar a lua foi Luna\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d813b9061b08",
        "outputId": "e8ed3f5e-3833-4b64-fa51-214b46dfe55f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " No elephant has ever visited the moon.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Who was the first elephant to visit the moon?\"\n",
        "\n",
        "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-mvIN9SPIy6"
      },
      "source": [
        "√â evidente que o chatbot est√° alucinando, j√° que nenhum elefante jamais voou para a lua. Mas como podemos evitar este tipo de perguntas inadequadas e, mais especificamente, reduzir as alucina√ß√µes?\n",
        "\n",
        "Existe um m√©todo poss√≠vel chamado prompt Determine Appropriate Response (DARE), que usa habilmente o pr√≥prio LLM para decidir se deve responder a uma pergunta com base em qual √© sua miss√£o.\n",
        "\n",
        "Vamos ver como funciona criando um chatbot para um site de viagens com um leve toque diferente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zA6Fd4ZAPIy7",
        "outputId": "b1e932fe-6045-4ef0-e476-9dd9c8feedfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultiCandidateTextGenerationResponse(text=\" Hello! I'm here to help you plan your next trip. Whether you're looking for a relaxing beach vacation or an adventurous city getaway, I can help you find the perfect destination and activities for your budget and interests.\", _prediction_response=Prediction(predictions=[{'candidates': [{'content': \" Hello! I'm here to help you plan your next trip. Whether you're looking for a relaxing beach vacation or an adventurous city getaway, I can help you find the perfect destination and activities for your budget and interests.\", 'author': '1'}], 'groundingMetadata': [{}], 'citationMetadata': [{'citations': []}], 'safetyAttributes': [{'blocked': False, 'safetyRatings': [{'probabilityScore': 0.1, 'severityScore': 0.1, 'severity': 'NEGLIGIBLE', 'category': 'Dangerous Content'}, {'probabilityScore': 0.1, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Harassment'}, {'probabilityScore': 0.0, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Hate Speech'}, {'probabilityScore': 0.3, 'severityScore': 0.1, 'severity': 'NEGLIGIBLE', 'category': 'Sexually Explicit'}], 'scores': [0.1, 0.1, 0.1, 0.3], 'categories': ['Finance', 'Insult', 'Profanity', 'Sexual']}]}], deployed_model_id='', metadata={'tokenMetadata': {'outputTokenCount': {'totalTokens': 46.0, 'totalBillableCharacters': 186.0}, 'inputTokenCount': {'totalBillableCharacters': 218.0, 'totalTokens': 64.0}}}, model_version_id='', model_resource_name='', explanations=None), is_blocked=False, errors=(), safety_attributes={'Finance': 0.1, 'Insult': 0.1, 'Profanity': 0.1, 'Sexual': 0.3}, grounding_metadata=GroundingMetadata(citations=[], search_queries=[]), candidates=[ Hello! I'm here to help you plan your next trip. Whether you're looking for a relaxing beach vacation or an adventurous city getaway, I can help you find the perfect destination and activities for your budget and interests.])\n"
          ]
        }
      ],
      "source": [
        "chat_model = ChatModel.from_pretrained(\"chat-bison@002\")\n",
        "\n",
        "chat = chat_model.start_chat()\n",
        "dare_prompt = \"\"\"Remember that before you answer a question, you must check to see if it complies with your mission.\n",
        "If not, you can say, Sorry I can't answer that question.\"\"\"\n",
        "\n",
        "print(\n",
        "    chat.send_message(\n",
        "        f\"\"\"\n",
        "Hello! You are an AI chatbot for a travel web site.\n",
        "Your mission is to provide helpful queries for travelers.\n",
        "\n",
        "{dare_prompt}\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCi_kDjHPIy7"
      },
      "source": [
        "Suponha que fa√ßamos uma pergunta simples sobre um dos pontos tur√≠sticos mais famosos da It√°lia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4b8AAsTPIy7",
        "outputId": "5615be28-e907-4f5c-e8e6-c3e55523ba9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultiCandidateTextGenerationResponse(text=\" There are many great places for sightseeing in Milan, Italy. Some of the most popular include:\\n\\n* The Duomo: This stunning Gothic cathedral is one of the most iconic landmarks in Milan. It took nearly 600 years to complete, and its intricate details are truly breathtaking.\\n* The Galleria Vittorio Emanuele II: This beautiful shopping arcade is located in the heart of Milan. It's home to some of the most luxurious shops in the world, as well as several cafes and restaurants.\\n* The Sforza Castle: This historic castle was once the home of the ruling Sforza family. Today, it houses several museums, including the Pinacoteca di Brera, which features a collection of Renaissance and Baroque art.\\n* The Parco Sempione: This large park is located just outside the city center. It's a great place to relax and enjoy the outdoors. There are several playgrounds, a lake, and even a small zoo.\\n* The Navigli: This network of canals is a popular spot for locals and tourists alike. You can take a boat ride along the canals, or simply stroll along the banks and enjoy the scenery.\", _prediction_response=Prediction(predictions=[{'candidates': [{'content': \" There are many great places for sightseeing in Milan, Italy. Some of the most popular include:\\n\\n* The Duomo: This stunning Gothic cathedral is one of the most iconic landmarks in Milan. It took nearly 600 years to complete, and its intricate details are truly breathtaking.\\n* The Galleria Vittorio Emanuele II: This beautiful shopping arcade is located in the heart of Milan. It's home to some of the most luxurious shops in the world, as well as several cafes and restaurants.\\n* The Sforza Castle: This historic castle was once the home of the ruling Sforza family. Today, it houses several museums, including the Pinacoteca di Brera, which features a collection of Renaissance and Baroque art.\\n* The Parco Sempione: This large park is located just outside the city center. It's a great place to relax and enjoy the outdoors. There are several playgrounds, a lake, and even a small zoo.\\n* The Navigli: This network of canals is a popular spot for locals and tourists alike. You can take a boat ride along the canals, or simply stroll along the banks and enjoy the scenery.\", 'author': 'bot'}], 'groundingMetadata': [{}], 'citationMetadata': [{'citations': []}], 'safetyAttributes': [{'blocked': False, 'safetyRatings': [{'probabilityScore': 0.1, 'severityScore': 0.1, 'severity': 'NEGLIGIBLE', 'category': 'Dangerous Content'}, {'probabilityScore': 0.1, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Harassment'}, {'probabilityScore': 0.0, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Hate Speech'}, {'probabilityScore': 0.2, 'severityScore': 0.1, 'severity': 'NEGLIGIBLE', 'category': 'Sexually Explicit'}], 'scores': [0.1, 0.2], 'categories': ['Insult', 'Sexual']}]}], deployed_model_id='', metadata={'tokenMetadata': {'outputTokenCount': {'totalTokens': 233.0, 'totalBillableCharacters': 886.0}, 'inputTokenCount': {'totalTokens': 122.0, 'totalBillableCharacters': 450.0}}}, model_version_id='', model_resource_name='', explanations=None), is_blocked=False, errors=(), safety_attributes={'Insult': 0.1, 'Sexual': 0.2}, grounding_metadata=GroundingMetadata(citations=[], search_queries=[]), candidates=[ There are many great places for sightseeing in Milan, Italy. Some of the most popular include:\n",
            "\n",
            "* The Duomo: This stunning Gothic cathedral is one of the most iconic landmarks in Milan. It took nearly 600 years to complete, and its intricate details are truly breathtaking.\n",
            "* The Galleria Vittorio Emanuele II: This beautiful shopping arcade is located in the heart of Milan. It's home to some of the most luxurious shops in the world, as well as several cafes and restaurants.\n",
            "* The Sforza Castle: This historic castle was once the home of the ruling Sforza family. Today, it houses several museums, including the Pinacoteca di Brera, which features a collection of Renaissance and Baroque art.\n",
            "* The Parco Sempione: This large park is located just outside the city center. It's a great place to relax and enjoy the outdoors. There are several playgrounds, a lake, and even a small zoo.\n",
            "* The Navigli: This network of canals is a popular spot for locals and tourists alike. You can take a boat ride along the canals, or simply stroll along the banks and enjoy the scenery.])\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What is the best place for sightseeing in Milan, Italy?\"\n",
        "print(chat.send_message(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPCNiR-ZPIy7"
      },
      "source": [
        "Agora vamos fingir que somos um usu√°rio n√£o t√£o legal e fazer ao chatbot uma pergunta que n√£o tem rela√ß√£o com viagens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvgDEvbZPIy7",
        "outputId": "d33c179a-b7e5-4a2f-c7a2-491bab5ea6da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultiCandidateTextGenerationResponse(text=\" Sorry, I can't answer that question. There have been no elephants on the moon.\", _prediction_response=Prediction(predictions=[{'candidates': [{'content': \" Sorry, I can't answer that question. There have been no elephants on the moon.\", 'author': 'bot'}], 'groundingMetadata': [{}], 'citationMetadata': [{'citations': []}], 'safetyAttributes': [{'blocked': False, 'safetyRatings': [{'probabilityScore': 0.0, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Dangerous Content'}, {'probabilityScore': 0.1, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Harassment'}, {'probabilityScore': 0.1, 'severityScore': 0.1, 'severity': 'NEGLIGIBLE', 'category': 'Hate Speech'}, {'probabilityScore': 0.1, 'severityScore': 0.1, 'severity': 'NEGLIGIBLE', 'category': 'Sexually Explicit'}], 'scores': [0.1, 0.1, 0.3, 0.2, 0.1, 0.1, 0.1], 'categories': ['Death, Harm & Tragedy', 'Derogatory', 'Finance', 'Health', 'Insult', 'Legal', 'Sexual']}]}], deployed_model_id='', metadata={'tokenMetadata': {'outputTokenCount': {'totalTokens': 19.0, 'totalBillableCharacters': 65.0}, 'inputTokenCount': {'totalTokens': 365.0, 'totalBillableCharacters': 1373.0}}}, model_version_id='', model_resource_name='', explanations=None), is_blocked=False, errors=(), safety_attributes={'Death, Harm & Tragedy': 0.1, 'Derogatory': 0.1, 'Finance': 0.3, 'Health': 0.2, 'Insult': 0.1, 'Legal': 0.1, 'Sexual': 0.1}, grounding_metadata=GroundingMetadata(citations=[], search_queries=[]), candidates=[ Sorry, I can't answer that question. There have been no elephants on the moon.])\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Who was the first elephant to visit the moon?\"\n",
        "print(chat.send_message(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqCQcHqBPIy7"
      },
      "source": [
        "Voc√™ pode ver que o prompt do DARE adicionou uma camada de 'safetyAttributes' que evitou que o chatbot se desviasse do curso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "029e23abfd56"
      },
      "source": [
        "### Transforme tarefas generativas em tarefas de classifica√ß√£o para reduzir a variabilidade de resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d943941d6e59"
      },
      "source": [
        "#### Tarefas generativas levam a maior variabilidade de produ√ß√£o\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37528e6c9754"
      },
      "source": [
        "A solicita√ß√£o abaixo resulta em uma resposta aberta, √∫til para brainstorming, mas a resposta √© altamente vari√°vel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8e2dc39e9ae"
      },
      "outputs": [],
      "source": [
        "prompt = \"I'm a high school student. Recommend me a programming activity to improve my skills.\"\n",
        "\n",
        "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f71a6fa2b4bb"
      },
      "source": [
        "#### As tarefas de classifica√ß√£o reduzem a variabilidade de sa√≠da"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "917517465dac"
      },
      "source": [
        "O prompt abaixo resulta em uma escolha e pode ser √∫til se voc√™ quiser que a sa√≠da seja mais f√°cil de controlar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3feb93d9df81"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"I'm a high school student. Which of these activities do you suggest and why:\n",
        "a) learn Python\n",
        "b) learn JavaScript\n",
        "c) learn Fortran\n",
        "\"\"\"\n",
        "\n",
        "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32290ac9fb2b"
      },
      "source": [
        "### Melhore a qualidade da resposta incluindo exemplos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "132834f5db2c"
      },
      "source": [
        "Outra maneira de melhorar a qualidade da resposta √© adicionar exemplos ao seu prompt. O LLM aprende no contexto a partir dos exemplos sobre como responder. Normalmente, um a cinco exemplos (disparos) s√£o suficientes para melhorar a qualidade das respostas. Incluir muitos exemplos pode fazer com que o modelo se ajuste demais aos dados e reduza a qualidade das respostas.\n",
        "\n",
        "Semelhante ao treinamento de modelo cl√°ssico, a qualidade e distribui√ß√£o dos exemplos s√£o muito importantes. Escolha exemplos que sejam representativos dos cen√°rios que voc√™ precisa que o modelo aprenda e mantenha a distribui√ß√£o dos exemplos (por exemplo, n√∫mero de exemplos por classe no caso de classifica√ß√£o) alinhada com sua distribui√ß√£o real."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46520d938b6a"
      },
      "source": [
        "#### Alerta de disparo zero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46d3b47e6cea"
      },
      "source": [
        "Abaixo est√° um exemplo de prompt zero-shot, onde voc√™ n√£o fornece nenhum exemplo ao LLM dentro do pr√≥prio prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cbe03eb0b71"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
        "\n",
        "Tweet: I loved the new YouTube video you made!\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0daabca1359"
      },
      "source": [
        "#### Alerta de disparo √∫nico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42c4652fc5c2"
      },
      "source": [
        "Abaixo est√° um exemplo de solicita√ß√£o √∫nica, onde voc√™ fornece um exemplo ao LLM dentro da solicita√ß√£o para fornecer alguma orienta√ß√£o sobre o tipo de resposta que deseja."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfe584860787"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
        "\n",
        "Tweet: I loved the new YouTube video you made!\n",
        "Sentiment: positive\n",
        "\n",
        "Tweet: That was awful. Super boring üò†\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef58c35005c0"
      },
      "source": [
        "\n",
        "#### Solicita√ß√£o de poucos disparos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b630e8947b60"
      },
      "source": [
        "Abaixo est√° um exemplo de prompt de poucas tentativas, onde voc√™ fornece alguns exemplos ao LLM dentro do prompt para fornecer alguma orienta√ß√£o sobre o tipo de resposta que deseja."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb3ba21bbd11"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
        "\n",
        "Tweet: I loved the new YouTube video you made!\n",
        "Sentiment: positive\n",
        "\n",
        "Tweet: That was awful. Super boring üò†\n",
        "Sentiment: negative\n",
        "\n",
        "Tweet: Something surprised me about this video - it was actually original. It was not the same old recycled stuff that I always see. Watch it - you will not regret it.\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "print(generation_model.predict(prompt=prompt, max_output_tokens=256).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4023be726eb"
      },
      "source": [
        "#### Escolhendo entre m√©todos de solicita√ß√£o de disparo zero, disparo √∫nico e poucos disparos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d7870ff75cc"
      },
      "source": [
        "A t√©cnica imediata a ser usada depender√° exclusivamente do seu objetivo. Os prompts de disparo zero s√£o mais abertos e podem fornecer respostas criativas, enquanto os prompts de disparo √∫nico e de poucos disparos ensinam o modelo como se comportar para que voc√™ possa obter respostas mais previs√≠veis que sejam consistentes com os exemplos fornecidos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-cpu.2-16.m124",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-16:m124"
    },
    "kernelspec": {
      "display_name": "Python 3 (Local)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}